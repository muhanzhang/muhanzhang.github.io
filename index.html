<!DOCTYPE html>
<html lang='en'>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content='IE=edge'>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Muhan Zhang's homepage">
	<meta name="author" content="Muhan Zhang">
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114851970-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'UA-114851970-1');
		gtag('config', 'UA-114851970-2');
	</script>
	<style type="text/css">
		body {
			font: 90%/1.2 Verdana, Arial, Helvetica, sans-serif;
			margin: 0;
			padding: 0;
			color: #000;
		}

		h1 {
			background-color: white;
			color: #3477D5;
			text-align: center;
			font-family: "sans serif";
			padding: 20px;
		}

		:root {
			--main-bg-color: "red";
		}

		.container {
			width: 960px;
			margin: 0 auto;
			/* the auto value on the sides, coupled with the width, centers the layout */
			overflow: hidden;
			/* this declaration makes the .container understand where the floated columns within ends and contain them */
			padding-top: 30px;
		}

		#visitor {
			color: white;
		}

		.sidebar1 {
			float: left;
			width: 200px;
			background-color: #CBDDF6;
			padding-bottom: 5px;
		}

		.content {
			width: 650px;
			padding-left: 35px;
			padding-right: 10px;
			float: left;
		}

		.sidebar1 li {
			list-style-type: none;
		}

		.MsoNormal {
			font-family: 'Georgia', 'serif';
		}

		.pub li {
			font: 220 12px/1.5;
		}

		p {
			font-family: verdana;
			font-size: 14px;
		}

		p2 {
			font-family: verdana;
			font-size: 13px;
		}

		p3 {
			font-family: verdana;
			font-size: 12px;
		}

		li p {
			font: 200 12px/1.5 Georgia, Times New Roman, serif;
		}

		li {
			padding: 10px;
			overflow: auto;
		}

		ul {
			list-style-type: none;
			margin: 0;
			padding: 0;
		}
	</style>
	<title>Muhan Zhang's Homepage</title>
</head>

<body>
	<!-- <div id="header"><h1>Homepage of Muhan Zhang (张牧涵)</h1> </div> -->
	<div class="container">
		<div class="sidebar1">
			<img src="./MuhanAtOfficeNano.png" 
             alt="Muhan at Office" 
             width="200" 
             height="266.67"
             onclick="this.src=this.src.includes('Nano') ? './muhanAtOffice.jpg' : './MuhanAtOfficeNano.png'">
			<!--<img src="./muhan.jpeg" width="250" height="420" alt="picture" /> -->
			<!--<li><a href="CV_Muhan_Zhang.pdf">My CV</a></li> -->
			<li><a href="#research">Research</a></li>
			<li><a href="#pub">Publications</a></li>
			<!-- <li><a href="#group">Group</a></li> -->
			<li><a href="#code">Software</a></li>
			<!-- 			<li><a href="mailto:muhan@wustl.edu">Contact me</a></li>
 -->
		</div>
		<div class="content">
			<div class="info">
				<h2 style="color:#3477D5;font-family:serif;font-size:28px;margin-top:0px"><a name="name">Muhan Zhang
						(张牧涵)</a></h2>
				<p style="font-family:serif;font-size:16px"> Email: muhan "at" pku "dot" edu "dot" cn <br>
					<a target="_blank" href="https://scholar.google.com.hk/citations?user=OBBqkosAAAAJ&hl=en">Google
						Scholar</a>,
					<a target="_blank" href="https://github.com/muhanzhang">Github</a>,
					<a target="_blank" href="http://mulabpku.com/">Lab Homepage</a>,
					<a target="_blank" href="https://github.com/MuLabPKU">Lab Github</a>
				</p>
				<hr>
			</div>

			<div class="bio">
				<h3><a name="bio">Biography</a></h3>
				<!--<h3><a name="bio">Biography</a> <a href="CV_Muhan_Zhang.pdf">(CV)</a></h3>-->
				<p> Muhan is a tenure-track assistant professor and PhD advisor in the <a target="_blank"
						href="http://www.ai.pku.edu.cn/">Institute for Artificial Intelligence</a> of Peking University
					</a>.
					Before coming back to China, he was a research scientist in Facebook AI (now Meta AI)
					working on large-scale graph
					learning systems and problems (2019-2021). He received his PhD degree in computer science from
					Washington University in St. Louis (2015-2019), advised by Prof. <a target="_blank"
						href="http://www.cse.wustl.edu/~ychen/">Yixin Chen</a>. Before WashU, he obtained a bachelor
					degree
					from Shanghai Jiao Tong University as a member of <a target="_blank"
						href="http://english.seiee.sjtu.edu.cn/english/info/8338.htm">the IEEE pilot class</a>, where he
					worked with Prof. <a target="_blank" href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a> and
					Prof. <a target="_blank" href="https://icne.sjtu.edu.cn/info/1026/1045.htm">Wenjun Zhang</a>.</p>
				<!-- He did an internship at the Core Data Science and Feed Science teams of Facebook as a research scientist in the summer of 2018, working with <a target="_blank" href="http://anandbhaskar.me/">Anand Bhaskar</a>.-->
				<p>张牧涵博士，北京大学人工智能研究院助理教授、研究员、博士生导师、院长助理。首届国家级青年人才项目（海外）获得者，北京大学博雅青年学者、未名青年学者。主持多项国自然、科技部、地方政府项目和课题，包括科技创新2030重大项目课题、国自然面上项目等，内容涵盖图神经网络、电路设计、药物分子设计、通用视觉、知识图谱、智慧司法等。研究受到华为、腾讯、阿里、蚂蚁、百度、理想、灵均等企业资助，涵盖大语言模型高效微调、推理、加速、图基础模型等。常年担任NeurIPS、ICML、ICLR、CVPR等顶级学术会议的领域主席。主要研究方向包括图机器学习、大语言模型架构和推理、智慧司法等，在国际上处于领先地位。Google Scholar总引用量超过10000次，其中两篇一作文章引用量分别达到2500+和2000+次，入选Elsevier全球前2%顶尖科学家。担任北大通用人工智能实验班（通班）23级班主任，主讲北京大学《人工智能引论》（本科）和《机器学习》（本研）课程。张牧涵博士于2015年本科毕业于上海交通大学IEEE试点班，2019年获得美国华盛顿大学（圣路易斯）计算机科学博士学位，曾于2019至2021年担任Facebook AI（现Meta AI）研究科学家，负责十亿用户级别大规模图机器学习系统的开发和研究。</p>
			</div>

			<div class="research">
				<h3><a name="research">Research Interests</a></h3>
				<p><strong>Graph machine learning</strong>. Many real-world problems are inherently graph-structured,
					e.g.,
					social networks, biological networks, World Wide Web, molecules, circuits, brain, road networks,
					knowledge graphs. Many machine learning algorithms are also defined on graphs, such as neural
					networks and graphical models. In this field, I develop algorithms and theories for learning over
					graphs, and apply them to problems like link prediction, graph classification, graph structure
					optimization, and knowledge graph reasoning. I am also interested in practical applications of graph
					neural networks, including brain modeling, drug discovery, circuit design, and healthcare
					applications.
				<p>
				<p><strong>Large language models</strong>. Compared to machine, human posesses extreme
					flexibility in handling unseen tasks in a few-shot/zero-shot way, much of which is attributed to
					human's system-II intelligence for complex logical reasoning, task planning, causal reasoning, and
					inductive generalization. Large language models (LLMs) have shown unprecedented improvement on such
					abilities, while still fail in some top-human-level tasks, such as scientific innovation, software 
					engineering, super-long writing, autonomous agents, etc.
					In this field, we aim to 1) design next-generation LLM architectures with 
					long-term memory, human-like learning mechanisms, fast training/inference, and superior long-context 
					abilities, 2) understand and improve LLMs' reasoning ability, ultimately matching or 
					outperforming human on the most challenging tasks, 
					and 3) explore LLMs' integration with other modalities, such as graph, code, relational 
					database (RDB), image, video, etc.
					<hr>
			</div>

			<div class="hiring">
				<h3><a name="hiring">Prospective Students</a> </h3>
				<p>
					I am looking for highly motivated PhD/undergraduate students who are interested in doing machine learning
					research with me. A successful AI researcher usually possesses the following properties:
					1) creativity and passion for research,
					2) solid coding skills,
					3) solid math skills,
					4) strong motivation for success.
					Please shoot me an email if you are passionate about doing ground-breaking research with me, and are willing to 
					exercise your every necessary ability towards it. 
					I will do my best to provide support for your success, including detailed guidance, plenty of
					computation resources, and research freedom for senior PhDs. You are especially welcome if you have
					interdisciplinary backgrounds (such as maths/physics/chemistry/biology) while can write code.
					For students in Peking University, you can schedule one on one chats with me at my office.

					<br>
					<br>
					Due to the large number of applicants, the competition is intense every year and I may not be able
					to
					respond to every email. Hope you understand!
					<br>
					<br>

					For potential PhD students: I am mainly affiliated with the Insitute for AI (人工智能研究院), which is
					based in the main campus (燕园) of PKU. Your office will also be there and you don't need to go to
					the Changping (昌平) campus.
				</p>
				<hr>
			</div>

			<div class="news">
				<h3><a name="news">News</a></h3>

				<div style="overflow-y: scroll; height:400px;">
                                <p2> 9/19/2025: Four papers accepted at
                                    NeurIPS-25! Congrats to Fanxu, Pingzhi,
                                    Juntong, Yi, Shijia
                                    and Yanan!
                                    <br />
                                </p2>
                                <br>
                                <p2> 9/19/2025: LooGLEv2 and PHYBench accepted
                                    at
                                    NeurIPS-25 Datasets and Benchmarks track!
                                    Congrats to Ziyuan, Yuxuan, Jiaqi and Shi!
                                    <br />
                                </p2>
                                <br>
                                <p2> 9/15/2025: HD-PiSSA is accepted at EMNLP-25
                                    as an oral presentation!
                                    Congrats to Yiding and Fanxu!
                                    <br />
                                </p2>
                                <br>
                                <p2>
                                    8/5/2025: One paper accepted at CIKM-25!
                                    Congrats to Weishuo!
                                    <br />
                                </p2>
                                <br>					
					<p2> 5/1/2025:
						Three papers accepted at ICML-25! Congrats to Fanxu, Yanbo and Zian!
						<br />
					</p2>
					<br>
					<p2> 1/23/2025:
						Three papers accepted at ICLR-25! Congrats to Lecheng, Haotong and Zian!
						<br />
					</p2>
					<br>
					<p2> 1/20/2025:
						Collaborated with RedNote and released RedStar, a long-chain-of-thought O1-like model that
						can
						perform complex mathematical, code and general reasoning. <a
							href="https://arxiv.org/pdf/2501.11284">See the preprint</a>.
						<br />
					</p2>
					<br>
					<p2> 12/18/2024:
						Released LIFT, a new paradigm to address long context problems of LLMs by fine-tuning the
						long input into model parameters. The LIFT framework can "lift" any short-context model by
						enabling them to handle arbitrary long contexts. <a href="https://arxiv.org/pdf/2412.13626">See
							the preprint</a>.
						<br />
					</p2>
					<br>
					<p2> 11/7/2024:
						Why do SOTA LLMs tend to think 9.11 > 9.9? Do they really understand numbers? We open-sourced <a
							href="https://arxiv.org/pdf/2411.03766">NUPA</a> studying the Numerical Understanding and
						Processing Abilities of LLMs, which contains a benchmark of 4 numerical representations and 17
						distinct tasks.
						<br />
					</p2>
					<br>
					<p2> 9/27/2024:
						I wrote a <a href="https://arxiv.org/pdf/2409.14179">draft</a> on the lexical invariance problem
						on multisets and graphs, proving the necessary
						and sufficient conditions for a lexical invariant function on multisets and graphs,
						respectively.
						<br />
					</p2>
					<br>
					<p2> 9/26/2024:
						Four papers accepted at NeurIPS-24! Congrats to Fanxu, Cai, Xiaojuan and Yanbo!
						<br />
					</p2>
					<br>
					<p2> 7/12/2024:
						We released GOFA, the <a href="https://arxiv.org/pdf/2407.09709">Generative One For All</a>
						model
						towards tackling all tasks on all kinds of graphs.
						<br />
					</p2>
					<br>
					<p2> 6/24/2024:
						We proposed an <a href="https://arxiv.org/pdf/2406.07926">efficient neural common neighbor</a>
						method for temporal graph link prediction, which achieves three new SoTA results on TGB.
						<br />
					</p2>
					<br>
					<p2> 5/17/2024:
						1 paper accepted at KDD-24! Congrats to Zuoyu!
						<br />
					</p2>
					<br>
					<p2> 5/16/2024:
						2 papers accepted at ACL-24! Congrats to Jiaqi and Xiaojuan!
						<br />
					</p2>
					<br>
					<p2> 5/2/2024:
						3 papers accepted at ICML-24! Congrats to Yi, Xiyuan and Yanbo!
						<br />
					</p2>
					<br>
					<p2> 4/13/2023: Invited by <a href="https://www.huawei.com/cn/">Huawei</a> to give a talk on <a
							href="https://arxiv.org/pdf/2404.02948" target="_blank">PiSSA: Principal Singular
							Values and Singular Vectors Adaptation of Large Language Models</a> and <a
							href="https://arxiv.org/pdf/2402.17709" target="_blank">Case-Based or Rule-Based: How Do
							Transformers Do the Math?
						</a>".<br />
					</p2>
					<br>

					<p2> 4/3/2024:
						We proposed a parameter-efficient fine-tuning method called PiSSA, which surpasses the
						fine-tuning effectiveness of the widely used LoRA on mainstream datasets and models without
						additional cost. A free lunch for PEFT! See
						preprint
						at <a href="https://arxiv.org/pdf/2404.02948.pdf" target="_blank">PiSSA: Principal Singular
							Values and Singular Vectors Adaptation of Large Language Models
						</a>.
						<br />
					</p2>
					<br>

					<p2> 2/1/2024: Invited by <a href="https://www.alibabacloud.com">Alibaba Cloud</a> and <a
							href="https://tongyi.aliyun.com/">Tongyi Lab</a> to give a talk on "<a
							href="https://openreview.net/pdf?id=4IT2pgc9v6">One for All: Towards Training One Graph
							Model for All Classification Tasks</a>".<br />
					</p2>
					<br>
					<p2> 1/17/2024:
						5 papers accepted at ICLR-24! Congrats to Hao, Xiyuan, Yinan, Zehao, and Ling!
						<br />
					</p2>
					<br>

					<p2> 10/17/2023: We introduce a theoretical framework that views complex answer generation in large
						language models as a hierarchical "template-content" structure, which can explain how LLMs
						decompose tasks and perform complex reasoning. See preprint at <a
							href="https://arxiv.org/pdf/2310.05452.pdf" target="_blank">Explaining
							the Complex Task Reasoning of Large Language Models with Template-Content Structure
						</a>.
						<br />
					</p2>
					<br>

					<p2> 9/22/2023:
						5 papers accepted at NeurIPS-23! Congrats to Lecheng, Jiarui, Zian, Junru and Cai!
						<br />
					</p2>
					<br>

					<p2> 6/5/2023:
						We proposed (k,t)-FWL+, a subgraph GNN achieving new state-of-the-art results on ZINC. See
						preprint
						at <a href="https://arxiv.org/pdf/2306.03266.pdf" target="_blank">Towards
							Arbitrarily
							Expressive GNNs in O(n<sup>2</sup>) Space by Rethinking Folklore Weisfeiler-Lehman
						</a>.
						<br />
					</p2>
					<br>
					<p2> 5/29/2023:
						We introduced code prompting, a neural-symbolic prompting method that uses code as intermediate
						steps to improve LLMs' reasoning ability. See preprint
						at <a href="https://arxiv.org/pdf/2305.18507.pdf" target="_blank">Code Prompting: a
							Neural Symbolic Method for Complex Reasoning in Large Language Models
						</a>.
						<br />
					</p2>
					<br>

					<p2> 5/24/2023:
						We systematically tested LLMs' inductive, deductive, and
						abductive reasoning abilities, and found that their performance dropped a lot when replacing
						natural language with symbols. See preprint at <a href="https://arxiv.org/pdf/2305.14825.pdf"
							target="_blank">Large Language
							Models are In-Context Semantic Reasoners rather than Symbolic Reasoners
						</a>.
						<br />
					</p2>
					<br>

					<p2> 5/31/2023: Gave a talk on "<a href="https://arxiv.org/pdf/2302.05743.pdf">Is Distance Matrix
							Enough for Geometric Deep Learning?</a>" at <a
							href="https://www.amazonaws.cn/en/ailab/">Amazon Web Services AI Shanghai Lablet</a>.<br />
					</p2>
					<br>

					<p2> 5/8/2023: We constructed BREC: a new comprehensive dataset for evaluating GNN
						expressiveness. The arxiv link of our manuscript is <a
							href="https://arxiv.org/pdf/2304.07702.pdf"
							target="_blank">https://arxiv.org/pdf/2304.07702.pdf</a>.
						The dataset and
						evaluation code are at <a href="https://github.com/GraphPKU/BREC"
							target="_blank">https://github.com/GraphPKU/BREC</a>. We welcome suggestions, contributions
						or collaborations to improve BREC.
						<br />
					</p2>
					<br>
					<p2> 4/25/2023: One paper accepted at ICML-23! <a href="https://arxiv.org/pdf/2305.04963.pdf"
							target="_blank">From Relational Pooling to Subgraph GNNs</a>. Congrats to Cai and Xiyuan!
						<br />
					</p2>
					<br>
					<p2> 4/20/2023: We provided a complete theory of using graph neural networks (GNNs) for multi-node
						representation learning with labeling tricks, extending our original labeling trick paper. The
						arxiv link of our manuscript is <a href="https://arxiv.org/pdf/2304.10074.pdf"
							target="_blank">https://arxiv.org/pdf/2304.10074.pdf</a>
						<br />
					</p2>
					<br>
					<p2> 4/18/2023:
						We proposed Neural Common Neighbor (NCN) for link prediction. The preprint
						can be found at <a href="https://arxiv.org/pdf/2302.00890.pdf" target="_blank">Neural Common
							Neighbor with Completion for Link Prediction
						</a>.
						<br />
					</p2>
					<br>
					<p2> 1/21/2023: Two papers accepted at ICLR-23! <a href="https://openreview.net/pdf?id=kDSmxOspsXQ"
							target="_blank">I<sup>2</sup>-GNNs</b></a> and <a
							href="https://openreview.net/pdf?id=NE2911Kq1sp">Circuit Graph Neural Network</a>.
						I<sup>2</sup>-GNNs is the first linear-time GNN model to count 6-cycles.
						Congrats to Yinan and Zehao!
						<br />
					</p2>
					<br>
					<p2> 11/24/2022: Two papers accepted at LoG-22! <a href="https://openreview.net/pdf?id=0lSm-R82jBW"
							target="_blank">Graph
							Neural Network with Local Frame</a> and <a
							href="https://openreview.net/pdf?id=ha9hPpthvQ">Subgraph-aware Weisfeiler-Lehman</a>.
						Congrats to Xiyuan and Zhaohui!
						<br />
					</p2>
					<br>
					<p2> 11/18/2022: Invited by <a href="https://www.biomap.com/en/team" target="_blank">BioMap</a> to
						give a talk on
						3DLinker!
						<br />
					</p2>
					<br>
					<p2> 9/15/2022: Three papers accepted at NeurIPS-22! <a
							href="https://openreview.net/pdf?id=5xiLuNutzJG" target="_blank">Rethinking KG
							evaluation</a>,
						<a href="https://openreview.net/pdf?id=nN3aVRQsxGd" target="_blank">K-hop GNN</a>, and <a
							href="https://openreview.net/pdf?id=6pC5OtP7eBx" target="_blank">Geodesic GNN</a>.
						Rethinking KG
						evaluation is
						accepted as an oral presentation!
						Congrats to Haotong, Jiarui and Lecheng!
						<br />
					</p2>
					<br>

					<p2> 7/26/2022: Gave a talk on "How Powerful are Spectral Graph Neural Networks" at <a
							href="https://ins.sjtu.edu.cn/topics/seminar/ai-math-colloquia">"AI + Math" Colloquia</a> of
						Shanghai Jiao Tong University! <a href="https://ins.sjtu.edu.cn/seminars/2143
						">Video link</a> (in English).<br /></p2>
					<br>

					<p2> 7/9/2022: Gave a talk on "How Powerful are Spectral Graph Neural Networks" at <a
							href="https://mp.weixin.qq.com/s/-j26welb9v8jW2_PMzETtg" target="_blank">LOGS China</a>!
						Video link at <a href="https://www.bilibili.com/video/BV1eU4y1D7Gv?share_source=copy_web
					" target="_blank">Bilibili</a> (in Chinese).<br /></p2>
					<br>
					<p2> 5/16/2022: Three papers accepted at ICML-22! <a href="https://arxiv.org/pdf/2205.07309.pdf"
							target="_blank">3DLinker</a>, <a href="https://arxiv.org/pdf/2205.11172.pdf"
							target="_blank">JacobiConv</a>, and <a href="https://arxiv.org/pdf/2203.10304.pdf"
							target="_blank">PACE</a>. 3DLinker is accepted as a long
						presentation (118/5630)! Congrats to Yinan, Xiyuan and Zehao!<br /></p2>
					<br>
					<p2> 4/27/2022: Invited by Twitter (London and New York teams) to give a talk on Labeling Trick!
						<br />
					</p2>
					<br>
					<p2> 4/15/2022: I will serve as an area chair for NeurIPS-22. <br /></p2>
					<br>
					<p2> 4/9/2022: Invited by <a href="http://www.aitime.cn/" target="_blank">AI Time</a> to give a talk
						of <a href="https://www.bilibili.com/video/BV1JS4y127g6" target="_blank">Nested GNNs and
							ShaDow</a> in the AI2000
						Young Scientist Track!<br /></p2>
					<br>
					<p2> 3/6/2022: Elected to the 2022 <a
							href="https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962bde8" target="_blank"> AI
							2000 Most
							Influential Scholars</a> by AMiner. Ranked 66th globally in the AAAI/IJCAI category.<br />
					</p2>
					<br>
					<p2> 2/17/2022: Invited by <a href="http://www.aitime.cn/" target="_blank"> AI Time</a> to give a
						talk of <a
							href="https://www.bilibili.com/video/BV1Xr4y167uz?from=search&seid=9289606471070121701&spm_id_from=333.337.0.0"
							target="_blank">Labeling
							Trick</a>!<br /></p2>
					<br>
					<p2> 1/24/2022: Two papers accepted at ICLR-22! <a
							href="https://openreview.net/forum?id=XLxhEjKNbXj" target="_blank">Subgraph Representation
							Learning GNN</a>,
						<a href="https://openreview.net/forum?id=e95i1IHcWj" target="_blank">Positional Encoding for
							more powerful
							GNN</a>!<br />
					</p2>
					<br>
					<p2> 1/10/2022: Our Book <a href="https://link.springer.com/book/10.1007/978-981-16-6054-2"
							target="_blank">Graph
							Neural
							Networks: Foundations, Frontiers, and Applications</a> is published! A free version is
						available
						on
						the <a href="https://graph-neural-networks.github.io/index.html" target="_blank">GNN Book
							Website</a>. Happy to
						contribute one <a href="https://graph-neural-networks.github.io/gnnbook_Chapter10.html"
							target="_blank">chapter</a>
						on
						GNN for link prediction!<br /></p2>
					<br>
					<p2> 12/22/2021: I will serve as a meta-reviewer (area chair) for ICML-22. <br /></p2>
					<br>
					<p2> 12/19/2021: Glad to organize a <a href="https://pair2struct-workshop.github.io/"
							target="_blank">graph
							workshop</a>
						at
						ICLR-22: PAIR2Struct: Privacy, Accountability, Interpretability, Robustness, Reasoning on
						Structured
						Data. Welcome to contribute! <br /></p2>
					<br>
					<p2> 9/29/2021: Three papers accepted at NeurIPS! <a href="https://arxiv.org/pdf/2010.16103.pdf"
							target="_blank">Labeling
							Trick</a>, <a href="https://arxiv.org/pdf/2110.13197.pdf" target="_blank">Nested GNN</a> and
						<a href="https://arxiv.org/pdf/2012.01380.pdf" target="_blank">ShaDow GNN</a>!<br />
					</p2>
					<br>
					<p2> 9/16/2021: Gave a presentation on Labeling Trick at 4Paradigm!<br /></p2>
					<br>
					<p2> 8/19/2021: Gave a presentation on Labeling Trick at Remin University of China!<br /></p2>
					<br>
					<p2> 3/13/2021: I am going to join Peking University as an assistant professor starting from May
						2021.
						Welcome to apply for PKU!<br /></p2>
					<br>
				</div>
				<!-- <p2> 10/13/2020: SEAL achieved 1st places on 3 out of 4 OGB <a href="https://ogb.stanford.edu/docs/leader_linkprop/">leaderboard</a> link prediction tasks! Checkout our preprint <a href="https://arxiv.org/abs/2010.16103">paper</a>.<br /></p2>
				<br>
				<p2> 8/24/2020: Excited to give a keynote talk at the <a href="http://www.mlgworkshop.org/2020/">DLG/MLG workshop</a> of KDD 2020!<br /></p2>
				<br>
				<p2> 5/15/2020: HAP paper accepted at KDD 2020!<br /></p2>
				<br>
				<p2> 12/19/2019: IGMC paper accepted at ICLR 2020 as a spotlight presentation!<br /></p2>
				<br>
				<p2> 12/14/2019: Presented our D-VAE paper at NeurIPS 2019!<br /></p2>
				<br>
				<p2> 10/14/2019: Started full-time at Facebook!<br /></p2>
				<br>
				<p2> 9/30/2019: Successfully defended my PhD thesis on <a href="https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=1554&context=eng_etds">GNN</a>. Excited to complete PhD in 4 years!<br /></p2>
				<br>
				<p2> 3/8/2019: Had a wonderful journey at Amazon's Graduate Research Symposium. Make friends with a lot of young talented!<br /></p2>
				<br> -->
				<hr>
			</div>


			<div class="pub">
				<h3><a name="pub">Publications</a></h3>
				<ul class='pub'>
					<h3 style="font-size:15px"><a name="year">2025</a></h3>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25]</font></strong>
                                F. Meng*, P. Tang*, Z. Yao, X. Sun, and <strong>M.
                                    Zhang</strong>,
                                <b>TransMLA: Migrating GQA Models to MLA with
                                    Full DeepSeek Compatibility and Speedup</b>,
                                <em>Advances in Neural Information Processing
                                    Systems (NeurIPS-25)</em>, <font
                                    color=#FF4500>spotlight presentation</font>,
                                2025.
                                (<a
                                    href="https://arxiv.org/pdf/2502.07864">PDF</a>)
                                (<a href="https://github.com/fxmeng/TransMLA"
                                    target="_blank">Source code</a>)
                            </li>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25]</font></strong>
                                J. Wang, X. Wang, and <strong>M. Zhang</strong>,
                                <b>OCN: Effectively Utilizing Higher-Order
                                    Common Neighbors for Better Link
                                    Prediction</b>,
                                <em>Advances in Neural Information Processing
                                    Systems (NeurIPS-25)</em>, 2025.
                                (<a
                                    href="https://arxiv.org/pdf/2505.19719">PDF</a>)
                            </li>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25]</font></strong>
                                Y. Li, F. Meng, <strong>M. Zhang</strong>, S.
                                Zhu, S. Wang, and M. Xu,
                                <b>LoRASuite: Efficient LoRA Adaptation Across
                                    Large Language Model Upgrades</b>,
                                <em>Advances in Neural Information Processing
                                    Systems (NeurIPS-25)</em>, 2025.
                                (<a
                                    href="https://arxiv.org/pdf/2505.13515">PDF</a>)
                            </li>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25]</font></strong>
                                Y. Hu*, S. Kang*, H. Yang, H. Xu, and <strong>M.
                                    Zhang</strong>,
                                <b>Beyond Single-Task: Robust Multi-Task Length
                                    Generalization for LLMs</b>,
                                <em>Advances in Neural Information Processing
                                    Systems (NeurIPS-25)</em>, 2025.
                                (<a href="https://arxiv.org/pdf/2502.11525">PDF</a>)
                            </li>
							<li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25-Benchmark]</font></strong>
                                Z. He*, Y. Wang*, J. Li*, K. Liang, and <strong>M.
                                    Zhang</strong>,
                                <b>LooGLE v2: Are LLMs Ready for Real World Long
                                    Dependency Challenges?</b>,
                                <em>Advances in Neural Information Processing
                                    Systems, D&B Track
                                    (NeurIPS-25-Benchmark)</em>, 2025.
                            </li>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[NeurIPS-25-Benchmark]</font></strong>
                                S. Qiu, S. Guo, Z. Song, et al., <strong>M.
                                    Zhang</strong>, and H. X. Zhu,
                                <b>PHYBench: Holistic Evaluation of Physical
                                    Perception and Reasoning in Large Language
                                    Models</b>,
                                <em>Advances in Neural Information Processing
                                    Systems, D&B Track
                                    (NeurIPS-25-Benchmark)</em>, 2025.
                                (<a
                                    href="https://arxiv.org/pdf/2504.16074">PDF</a>)
                                (<a href="https://www.phybench.cn/"
                                    target="_blank">Source code</a>)
                            </li>					
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[EMNLP-25]</font></strong>
                                Y. Wang*, F. Meng*, X. Zhang, F. Jiang, P. Tang,
                                and <strong>M. Zhang</strong>,
                                <b>HD-PiSSA: High-Rank Distributed Orthogonal
                                    Adaptation</b>,
                                <em>Proc. Conference on Empirical Methods in
                                    Natural Language Processing (EMNLP-25)</em>,
                                <font color=#FF4500>oral
                                    presentation</font>
                                2025.
                                (<a
                                    href="https://arxiv.org/pdf/2505.18777">PDF</a>)
                                (<a href="https://github.com/MuLabPKU/HD-PiSSA"
                                    target="_blank">Source code</a>)
                            </li>
                            <li class=MsoNormal>
                                <strong><font
                                        color=#0aa0c0>[CIKM-25]</font></strong>
                                W. Ma, Y. Wang, X. Wang and <strong>M.
                                    Zhang</strong>,
                                <b>Reconsidering the Performance of GAE in Link
                                    Prediction</b>,
                                <em>Proc. ACM International Conference on
                                    Information and Knowledge Management
                                    (CIKM-25)</em>, 2025.
                                (<a
                                    href="https://arxiv.org/pdf/2411.03845">PDF</a>)
                                (<a
                                    href="https://github.com/GraphPKU/Refined-GAE"
                                    target="_blank">Source code</a>)
                            </li>					
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-25] </font>
						</strong>
						F. Meng, P. Tang, F. Jiang, and <strong>M. Zhang</strong>, <b>CLOVER: Cross-Layer Orthogonal
							Vectors Pruning and Fine-Tuning</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-25)</em>, 2025. (<a href="https://arxiv.org/pdf/2411.17426"
							target="_blank">PDF</a>))
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-25] </font>
						</strong> Y. Wang, X. Wang, Q. Gan, M. Wang, Q. Yang, D. Wipf, and <strong>M. Zhang</strong>,
						<b>Griffin: Towards a Graph-Centric Relational Database Foundation Model</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-25)</em>, 2025. (<a href="https://arxiv.org/pdf/2505.05568" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-25] </font>
						</strong> Z. Li, C. Zhou, X. Wang, X. Peng, and <strong>M. Zhang</strong>, <b>Geometric
							Representation Condition Improves Equivariant Molecule Generation</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-25)</em>, <font color=#FF4500>
							spotlight presentation (2.6% acceptance rate)</font>, 2025. (<a
							href="https://openreview.net/pdf?id=79O2XccGXZ" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[DAC-25] </font>
						</strong>G. Li, R. Xu, R. Xu, Y. Qiu, R. Tuerhong, <strong>M. Zhang</strong>, L. Ye and Y. Ma,
						<b>
							3D-SubG: A 3D Stacked Hybrid Processing Near/In-Memory Accelerator for Subgraph GNNs</b>,
						<em> Design Automation Conference (DAC-25)</em>, 2025.
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[JMLR-25] </font>
						</strong>X. Wang, P. Li, and <strong>M. Zhang</strong>,
						<b>
							Improving Graph Neural Networks on Multi-node Tasks with the Labeling Trick</b>,
						<em>Journal of Machine Learning Research (JMLR-25)</em>, 2025. (<a
							href="https://arxiv.org/pdf/2304.10074" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[SCSL@ICLR-25] </font>
						</strong> H. Yang, Q. Zheng, Y. Gao, Y. Yang, Y. He, Z. Lin, and <strong>M. Zhang</strong>,
						<b>
							VACT: A Video Automatic Causal Testing System and a Benchmark</b>,
						<em>Workshop on Spurious Correlation and Shortcut Learning: Foundations and Solutions,
							International Conference on Learning Representations (SCSL@ICLR-25)</em>, 2025. (<a
							href="https://arxiv.org/pdf/2503.06163?" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-25] </font>
						</strong> L. Kong, J. Feng, H. Liu, C. Huang, J. Huang, Y. Chen and <strong>M. Zhang</strong>,
						<b>
							GOFA: A Generative One-For-All Model for Joint Graph Language Modeling</b>,
						<em>International Conference on Learning Representations (ICLR-25)</em>, 2025. (<a
							href="https://openreview.net/pdf?id=mIjblC9hfm" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-25] </font>
						</strong> H. Yang, Y. Hu, S. Kang, Z. Lin and <strong>M. Zhang</strong>,
						<b>
							Number Cookbook: Number Understanding of Language Models and How to Improve It</b>,
						<em>International Conference on Learning Representations (ICLR-25)</em>, 2025. (<a
							href="https://openreview.net/pdf?id=BWS5gVjgeY" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-25] </font>
						</strong> Z. Li, X. Wang, S. Kang and <strong>M. Zhang</strong>,
						<b>
							On the Completeness of Invariant Geometric Deep Learning Models</b>,
						<em>International Conference on Learning Representations (ICLR-25)</em>, 2025. (<a
							href="https://openreview.net/pdf?id=52x04chyQs" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[ICLR-25-Blogpost] </font>
						</strong>F. Meng and <strong>M. Zhang</strong>, <b>Parameter-Efficient and Stable Singular Value
							Adaptation for Pre-Trained Models
						</b>, <em>Blogpost Track at International Conference on Learning Representations
							(ICLR-25-Blogpost)</em>, 2025. (<a href="https://arxiv.org/pdf/2411.17426">PDF</a>) (<a
							href="https://d2jud02ci9yv69.cloudfront.net/2025-04-28-pessa-189/blog/pessa/">Blogpost
							Url</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[Nature Communications] </font>
						</strong>X. Zhang, H. Lin, <strong>M. Zhang</strong>, Y. Zhou and J. Ma, <b>A data-driven group
							retrosynthesis planning model inspired by neurosymbolic programming
						</b>, <em>Nature Communications</em>, Volume 16, article number 192, 2025. (<a
							href="https://link.springer.com/article/10.1007/s10462-025-11114-z">PDF</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[Artif Intell Rev] </font>
						</strong>C. Sun, <strong>M. Zhang</strong>, J. Hu, H. Gu, J. Chen and M. Yang, <b>Adaptive
							graph diffusion networks: compact and expressive GNNs with large receptive fields
						</b>, <em>Artificial Intelligence Review</em>, Volume 58, article number 107, 2025. (<a
							href="https://link.springer.com/article/10.1007/s10462-025-11114-z">PDF</a>)
					</li>
					<h3 style="font-size:15px"><a name="year">2024</a></h3>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-24] </font>
						</strong>F. Meng, Z. Wang and <strong>M. Zhang</strong>, <b>PiSSA: Principal Singular Values and
							Singular Vectors Adaptation of Large Language Models
						</b>, <em>Advances in Neural Information Processing Systems
							(NeurIPS-24)</em>, <font color=#FF4500>
							spotlight presentation (2.08% acceptance rate)</font>, 2024. (<a
							href="https://arxiv.org/pdf/2404.02948">PDF</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-24] </font>
						</strong>C. Zhou, X. Wang and <strong>M. Zhang</strong>, <b>Latent Graph Diffusion: A Unified
							Framework for Generation and Prediction on Graphs
						</b>, <em>Advances in Neural Information Processing Systems
							(NeurIPS-24)</em>, 2024. (<a href="https://arxiv.org/pdf/2402.02518">PDF</a>)</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-24-Benchmark] </font>
						</strong>X. Tang, J. Li, Y. Liang, S. C. Zhu, <strong>M. Zhang#</strong> and Z. Zheng#, <b>Mars:
							Situated Inductive Reasoning in an Open-World Environment
						</b>, <em>Advances in Neural Information Processing Systems, D&B Track
							(NeurIPS-24-Benchmark)</em>, 2024. (<a href="https://arxiv.org/pdf/2410.08126">PDF</a>)</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-24-Benchmark] </font>
						</strong> <b>4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on
							Relational DBs
						</b>, <em>Advances in Neural Information Processing Systems, D&B Track
							(NeurIPS-24-Benchmark)</em>, 2024. (<a href="https://arxiv.org/pdf/2404.18209">PDF</a>)</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[KDD-24] </font>
						</strong>Z. Yan, J. Zhou, L. Gao#, Z. Tang and <strong>M. Zhang#</strong>, <b>An Efficient
							Subgraph
							GNN with Provable Substructure Counting Power
						</b>, <em>Proc. ACM SIGKDD Conference on
							Knowledge Discovery and Data Mining (KDD-24)</em>, 2024. (<a
							href="https://arxiv.org/pdf/2303.10576">PDF</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ACL-24] </font>
						</strong> J. Li, M. Wang, Z. Zheng and <strong>M. Zhang</strong>, <b>LooGLE: Can Long-Context
							Language Models Understand Long Contexts?</b>,
						<em>The 62nd Annual Meeting of the Association for Computational Linguistics (ACL-24)</em>,
						2024. (<a href="https://arxiv.org/pdf/2311.04939" target="_blank">PDF</a>)
						(<a href="https://github.com/bigai-nlco/LooGLE" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ACL-24] </font>
						</strong> X. Tang, S. C. Zhu, Y. Liang and <strong>M. Zhang</strong>, <b>RulE: Knowledge Graph
							Reasoning with Rule Embedding</b>,
						<em>Findings of the 62nd Annual Meeting of the Association for Computational Linguistics
							(ACL-24)</em>,
						2024. (<a href="https://arxiv.org/pdf/2210.14905" target="_blank">PDF</a>)
						(<a href="https://github.com/XiaojuanTang/RulE" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[TNNLS-24] </font>
						</strong> Z. Liu, F. Ji, J. Yang, X. Cao, <strong>M. Zhang</strong>, H. Chen and Y. Chang,
						<strong>Reﬁning Euclidean Obfuscatory Nodes Helps: A Joint-Space Graph Learning Method for Graph
							Neural Networks</strong>, &nbsp;<em>IEEE Transactions on Neural
							Networks
							and Learning Systems (TNNLS) </em>, 2024.
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[iScience-24] </font>
						</strong> X. Meng, X. Yan, K. Zhang, D. Liu, X. Cui, Y. Yang, <strong>M. Zhang</strong>, ...,
						and Y. Tang,
						<b>The application of large language models in medicine: A scoping review
						</b>,
						<em>iScience</em>, Volumn 27, Issue 5, May 2024. (<a
							href="https://www.cell.com/action/showPdf?pii=S2589-0042%2824%2900935-0"
							target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[JACT-24] </font>
						</strong> C. Wan, <strong>M. Zhang</strong>, P. Dang, W. Hao, S. Cao, P. Li and C. Zhang
						<b>Ambiguities in neural-network-based hyperedge prediction</b>,
						<em>Journal of Applied and Computational Topology</em>, May 2024. (<a
							href="https://link.springer.com/article/10.1007/s41468-024-00172-x" target="_blank">PDF</a>)
						(<a href="https://github.com/clwan/SNALS" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-24] </font>
						</strong> Y. Hu, X. Tang, H. Yang and <strong>M. Zhang</strong>, <b>Case-Based or Rule-Based:
							How
							Do Transformers Do the Math?</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-24)</em>, 2024. (<a href="https://arxiv.org/pdf/2402.17709" target="_blank">PDF</a>)
						(<a href="https://github.com/GraphPKU/Case_or_Rule" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-24] </font>
						</strong> X. Wang, P. Li and <strong>M. Zhang</strong>, <b>Graph As Point Set</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-24)</em>, 2024. (<a href="https://arxiv.org/pdf/2405.02795" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-24] </font>
						</strong> Y. Wang and <strong>M. Zhang</strong>, <b>An Empirical Study of Realized GNN
							Expressiveness</b>,
						<em>Proc. International Conference on Machine Learning
							(ICML-24)</em>, 2024. (<a href="https://openreview.net/pdf?id=WIaZFk02fI"
							target="_blank">PDF</a>) (<a href="https://github.com/brec-icml2024/brec-icml2024"
							target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[WWW-24] </font>
						</strong> H. Liu, J. Feng, L. Kong, D. Tao, Y. Chen and <strong>M. Zhang</strong>, <b>Graph
							Contrastive Learning Meets Graph Meta Learning: A Unified Method for Few-shot Node
							Tasks</b>,
						<em>The Web Conference (WWW-24)</em>, 2024. (<a href="https://arxiv.org/pdf/2309.10376.pdf"
							target="_blank">PDF</a>) (<a href="https://github.com/Haoliu-cola/COLA/"
							target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-24] </font>
						</strong> H. Liu, J. Feng, L. Kong, N. Liang, D. Tao, Y. Chen and <strong>M. Zhang</strong>,
						<b>One
							For All: Towards Training One Graph Model For All Classification Tasks</b>,
						<em>International Conference on Learning Representations (ICLR-24)</em>, <font color=#FF4500>
							spotlight presentation (4.96% acceptance rate)</font>, 2024. (<a
							href="https://openreview.net/pdf?id=4IT2pgc9v6" target="_blank">PDF</a>) (<a
							href="https://github.com/LechengKong/OneForAll" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-24] </font>
						</strong> X. Wang, H. Yang and <strong>M. Zhang</strong>, <b>Neural Common Neighbor with
							Completion
							for Link Prediction</b>,
						<em>International Conference on Learning Representations (ICLR-24)</em>, 2024. (<a
							href="https://arxiv.org/pdf/2302.00890" target="_blank">PDF</a>) (<a
							href="https://github.com/GraphPKU/NeuralCommonNeighbor" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-24] </font>
						</strong> Y. Huang, W. Lu, J. Robinson, Y. Yang, <strong>M. Zhang</strong>, S. Jegelka and P.
						Li,
						<b>
							On the Stability of Expressive Positional Encodings for Graph Neural Networks</b>,
						<em>International Conference on Learning Representations (ICLR-24)</em>, 2024. (<a
							href="https://openreview.net/pdf?id=xAqcJ9XoTf" target="_blank">PDF</a>) (<a
							href="https://github.com/Graph-COM/SPE" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-24] </font>
						</strong> Z. Dong, <strong>M. Zhang</strong>, P. Payne, M. Province, C. Cruchaga, T. Zhao, F.
						Li, Y. Chen, <b>Rethinking the Power of Graph Canonization in Graph Representation Learning
							with Stability</b>,
						<em>International Conference on Learning Representations (ICLR-24)</em>, 2024. (<a
							href="https://openreview.net/pdf?id=nTwb2vBLOV" target="_blank">PDF</a>)
					</li>

					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-24] </font>
						</strong> L. Yang, Y. Tian, M. Xu, Z. Liu, S. Hong, W. Qu, W. Zhang, B. Cui, <strong>M.
							Zhang#</strong> and J. Leskovec, <b>VQGraph: Rethinking Graph Representation Space for
							Bridging
							GNNs and MLPs</b>, <em>International Conference on Learning Representations (ICLR-24)</em>,
						2024. (<a href="https://arxiv.org/pdf/2308.02117.pdf" target="_blank">PDF</a>) (<a
							href="https://github.com/YangLing0818/VQGraph" target="_blank">Source code</a>)</li>

					<h3 style="font-size:15px"><a name="year">2023</a></h3>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-23] </font>
						</strong> J. Zhou, J. Feng, X. Wang and <strong>M. Zhang</strong>,
						<b>Distance-Restricted Folklore Weisfeiler-Lehman GNNs with Provable Cycle Counting Power</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-23)</em>, <font color=#FF4500>spotlight
							presentation (3.06% acceptance rate)</font>, 2023. (<a
							href="https://arxiv.org/pdf/2309.04941.pdf" target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-23] </font>
						</strong> Z. Li, X. Wang, Y. Huang and <strong>M. Zhang</strong>,
						<b>Is Distance Matrix Enough for Geometric Deep Learning?</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-23)</em>, 2023. (<a href="https://arxiv.org/pdf/2302.05743.pdf"
							target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-23] </font>
						</strong> L. Kong, J. Feng, H. Liu, D. Tao, Y. Chen and <strong>M. Zhang</strong>,
						<b>MAG-GNN: Reinforcement Learning Boosted Graph Neural Network</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-23)</em>, 2023. (<a href="https://arxiv.org/pdf/2310.19142.pdf"
							target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-23] </font>
						</strong> J. Feng, L. Kong, H. Liu, D. Tao, F. Li, <strong>M. Zhang</strong> and Y. Chen,
						<b>Extending the Design Space of Graph Neural Networks by Rethinking Folklore
							Weisfeiler-Lehman</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-23)</em>, 2023. (<a href="https://arxiv.org/pdf/2306.03266.pdf"
							target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-23] </font>
						</strong> C. Zhou, X. Wang and <strong>M. Zhang</strong>,
						<b>Facilitating Graph Neural Networks with Random Walk on Simplicial Complexes</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-23)</em>, 2023. (<a href="https://arxiv.org/pdf/2310.19285.pdf"
							target="_blank">PDF</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[VLDB-23] </font>
						</strong>H. Yin, <strong>M. Zhang</strong>, J. Wang and P. Li, <b>SUREL+: Moving from Walks to
							Sets for Scalable Subgraph-based Graph Representation Learning</b>, <em>Proc. of the VLDB
							Endowment (VLDB-23)</em>, volume 16, 2023. (<a href="https://arxiv.org/pdf/2303.03379.pdf"
							target="_blank">PDF</a>) (<a href="https://github.com/Graph-COM/SUREL_Plus"
							target="_blank">Source code</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-23] </font>
						</strong> C. Zhou, X. Wang and <strong>M. Zhang</strong>, <b>From Relational Pooling to Subgraph
							GNNs:
							A Universal Framework for More Expressive Graph Neural Networks</b>, <em>Proc. International
							Conference on Machine Learning
							(ICML-23)</em>, 2023. (<a href="https://arxiv.org/pdf/2305.04963.pdf"
							target="_blank">PDF</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-23] </font>
						</strong> Y. Huang, X. Peng, J. Ma, <strong>M. Zhang</strong>, <b>Boosting the Cycle Counting
							Power of Graph
							Neural Networks with I<sup>2</sup>-GNNs</b>, <em>International Conference on Learning
							Representations
							(ICLR-23)</em>, 2023. (<a href="https://openreview.net/pdf?id=kDSmxOspsXQ"
							target="_blank">PDF</a>) (<a href="https://github.com/GraphPKU/I2GNN" target="_blank">Source
							code</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-23] </font>
						</strong> Z. Dong, W. Cao, <strong>M. Zhang</strong>, D. Tao, Y. Chen, X. Zhang, <b>
							CktGNN: Circuit Graph Neural Network for Electronic Design Automation</b>, <em>International
							Conference on Learning Representations
							(ICLR-23)</em>, 2023. (<a href="https://openreview.net/pdf?id=NE2911Kq1sp"
							target="_blank">PDF</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ASP-DAC-23] </font>
						</strong> Y. Chen, J. Mai, X. Gao, <strong>M. Zhang</strong> and Y.
						Lin,
						<b>MacroRank: Ranking Macro Placement Solutions Leveraging Translation
							Equivariancy</b>, <em>28th Asia and South Pacific Design Automation
							Conference (ASP-DAC-23)</em>, 2023. (<a
							href="https://yibolin.com/publications/papers/PLACE_ASPDAC2023_Chen.pdf"
							target="_blank">PDF</a>)
					</li>
					<h3 style="font-size:15px"><a name="year">2022</a></h3>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[LoG-22] </font>
						</strong> X. Wang and <strong>M. Zhang</strong>,
						<b>Graph Neural Network with Local Frame for Molecular Potential Energy Surface</b>,
						<em>The First Learning on Graphs Conference (LoG-22)</em>, 2022. (<a
							href="https://openreview.net/pdf?id=0lSm-R82jBW">PDF</a>)(<a
							href="https://github.com/Xi-yuanWang/GNNLF" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[LoG-22] </font>
						</strong> Z. Wang, Q. Cao, H. Shen#, B. Xu, <strong>M. Zhang#</strong> and X. Cheng,
						<b>Towards Efficient and Expressive GNNs for Graph Classification via Subgraph-aware
							Weisfeiler-Lehman</b>,
						<em>The First Learning on Graphs Conference (LoG-22)</em>, 2022. (#corresponding author)(<a
							href="https://openreview.net/pdf?id=ha9hPpthvQ">PDF</a>)
					</li>

					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-22] </font>
						</strong> H. Yang, Z. Lin and <strong>M. Zhang</strong>,
						<b>Rethinking Knowledge Graph Evaluation Under the Open-World
							Assumption</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-22)</em>, <font color=#FF4500>oral presentation (1.7% acceptance rate)</font>,
						2022. (<a href="https://openreview.net/pdf?id=5xiLuNutzJG">PDF</a>)(<a
							href="https://github.com/GraphPKU/Open-World-KG" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-22] </font>
						</strong> J. Feng, Y. Chen, F. Li, A. Sarkar and <strong>M. Zhang</strong>,
						<b>How Powerful are K-hop Message Passing Graph Neural Networks</b>,
						<em>Advances in Neural Information Processing Systems
							(NeurIPS-22)</em>, 2022. (<a href="https://openreview.net/pdf?id=nN3aVRQsxGd">PDF</a>)(<a
							href="https://github.com/JiaruiFeng/KP-GNN" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[NeurIPS-22] </font>
						</strong> L. Kong, Y. Chen, <strong>M. Zhang</strong>,
						<b>Geodesic Graph Neural Network for Efficient Graph Representation
							Learning</b>, <em>Advances in Neural Information Processing Systems
							(NeurIPS-22)</em>, 2022. (<a href="https://openreview.net/pdf?id=6pC5OtP7eBx">PDF</a>)(<a
							href="https://github.com/woodcutter1998/gdgnn" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-22-DyNN] </font>
						</strong> Y. Yang, Y. Liang and <strong>M. Zhang</strong>, <b>PA-GNN: Parameter-Adaptive Graph
							Neural Networks
						</b>, <em>Workshop on Dynamic Neural Networks in International Conference on Machine Learning
							(ICML-22-DyNN-Workshop)</em>, <font color=#FF4500>oral presentation</font>, 2022.
						(<a href="https://dynn-icml2022.github.io/spapers/paper_6.pdf">PDF</a>) </li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[VLDB-22] </font>
						</strong> H. Yin, <strong>M. Zhang</strong>, Y. Wang, J. Wang and P. Li, <b>Algorithm and System
							Co-design for Efficient Subgraph-based Graph Representation Learning
						</b>, <em>Proc. of the VLDB Endowment (VLDB-22)</em>, volume 15, 2022.
						(<a href="https://www.vldb.org/pvldb/vol15/p2788-yin.pdf">PDF</a>)(<a
							href="https://github.com/Graph-COM/SUREL" target="_blank">Source code</a>) </li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-22] </font>
						</strong> Y. Huang, X. Peng, J. Ma, and <strong>M. Zhang</strong>, <b>3DLinker: An E(3)
							Equivariant Variational Autoencoder
							for Molecular Linker Design</b>, <em>Proc. International Conference on Machine Learning
							(ICML-22)</em>, <font color=#FF4500>long presentation</font>, 2022. (Only <font
							color=#FF4500>118 out of 5630</font> submissions are accepted as
						long presentations)
						(<a href="https://proceedings.mlr.press/v162/huang22g/huang22g.pdf">PDF</a>)(<a
							href="https://github.com/YinanHuang/3DLinker" target="_blank">Source code</a>) </li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-22] </font>
						</strong> X. Wang and <strong>M. Zhang</strong>, <b>How Powerful are Spectral Graph Neural
							Networks</b>, <em>Proc. International Conference on Machine Learning
							(ICML-22)</em>, 2022. (<a
							href="https://proceedings.mlr.press/v162/wang22am/wang22am.pdf">PDF</a>)(<a
							href="https://github.com/GraphPKU/JacobiConv" target="_blank">Source code</a>) </li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICML-22] </font>
						</strong> Z. Dong*, <strong>M. Zhang*</strong>, F. Li, and Y. Chen, <b>PACE: A Parallelizable
							Computation Encoder for Directed Acyclic Graphs</b>, <em>Proc. International Conference on
							Machine Learning
							(ICML-22)</em>, 2022. (*co-first author) (<a
							href="https://proceedings.mlr.press/v162/dong22b/dong22b.pdf">PDF</a>)(<a
							href="https://github.com/zehao-dong/PACE" target="_blank">Source code</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-22] </font>
						</strong> X. Wang and <strong>M. Zhang</strong>, <b>GLASS: GNN with Labeling Tricks for Subgraph
							Representation Learning</b>, <em>International Conference on Learning Representations
							(ICLR-22)</em>, 2022. (<a href="https://openreview.net/pdf?id=XLxhEjKNbXj">PDF</a>)(<a
							href="https://github.com/Xi-yuanWang/GLASS" target="_blank">Source code</a>)</li>
					<li class=MsoNormal><strong>
							<font color=#0aa0c0>[ICLR-22] </font>
						</strong> H. Wang, H. Yin, <strong>M. Zhang</strong>, and P. Li, <b>Equivariant and Stable
							Positional
							Encoding for More Powerful Graph Neural Networks</b>, <em>International Conference on
							Learning
							Representations (ICLR-22)</em>, 2022. (<a
							href="https://openreview.net/pdf?id=e95i1IHcWj">PDF</a>)(<a
							href="https://github.com/Graph-COM/PEG" target="_blank">Source code</a>)</li>

					<h3 style="font-size:15px"><a name="year">2021</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[MIA-21] </font>
						</strong>X. Li, Y. Zhou, N. Dvornek, <strong>M. Zhang</strong>, S. Gao, J. Zhuang, D. Scheinost,
						LH Staib, P. Ventola and JS Duncan, <b>Braingnn: Interpretable brain graph neural network for
							fmri analysis</b>, <em>Medical Image Analysis (MIA-21)</em>, 2021. (<a
							href="http://www.csce.uark.edu/~mqhuang/weeklymeeting/20220303_paper.pdf">PDF</a>) </li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-21] </font>
						</strong><strong>M. Zhang</strong>, P. Li, Y. Xia, K. Wang, and L. Jin, <b>Labeling Trick: A
							Theory
							of Using Graph Neural Networks for Multi-Node Representation Learning</b>, <em>Advances in
							Neural Information Processing Systems (NeurIPS-21)</em>, 2021. (<a
							href="https://arxiv.org/pdf/2010.16103.pdf">PDF</a>)(<a
							href="https://github.com/facebookresearch/SEAL_OGB" target="_blank">Source code</a>) </li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-21] </font>
						</strong><strong>M. Zhang</strong> and P. Li, <b>Nested Graph Neural Networks</b>, <em>Advances
							in Neural Information Processing Systems (NeurIPS-21)</em>, 2021.
						(<a href="https://arxiv.org/pdf/2110.13197.pdf">PDF</a>)
						(<a href="https://github.com/muhanzhang/NestedGNN" target="_blank">Source code</a>) </li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-21] </font>
						</strong>H. Zeng, <strong>M. Zhang#</strong>, Y. Xia, A. Srivastava, A. Malevich, R. Kannan, V.
						Prasanna, L. Jin, and R. Chen, <b>Decoupling the Depth and Scope of Graph Neural Networks</b>,
						<em>Advances in Neural Information Processing Systems (NeurIPS-21)</em>, 2021. (#corresponding
						author) (<a
							href="https://proceedings.neurips.cc/paper/2021/file/a378383b89e6719e15cd1aa45478627c-Paper.pdf">PDF</a>)(<a
							href="https://github.com/facebookresearch/shaDow_GNN" target="_blank">Source code</a>)
					</li>

					<h3 style="font-size:15px"><a name="year">2020</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[ICLR-20] </font>
						</strong><strong>M. Zhang</strong> and Y. Chen, <b>Inductive Matrix Completion Based on Graph
							Neural
							Networks</b>, <em>International Conference on Learning Representations (ICLR-20)</em>,
						<font color=#FF4500>spotlight
							presentation (4.16% acceptance rate)</font>, 2020. (<a
							href="https://openreview.net/pdf?id=ByxxgCEYDS">PDF</a>)(<a
							href="https://github.com/muhanzhang/IGMC" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[KDD-20] </font>
						</strong><strong>M. Zhang</strong>, C. King, M. Avidan, and Y. Chen, <b>Hierarchical Attention
							Propagation for Healthcare Representation Learning</b>, <em>Proc. ACM SIGKDD Conference on
							Knowledge Discovery and Data Mining (KDD-20)</em>, 2020. (<a
							href="http://muhanzhang.github.io/papers/KDD_2020.pdf">PDF</a>)(<a
							href="https://github.com/muhanzhang/HAP" target="_blank">Source code</a>)</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[MICCAI-20] </font>
						</strong>X. Li, Y. Zhou, N. Dvornek, <strong>M. Zhang</strong>, J. Zhuang, P. Ventola, and J.
						Duncan, <b>Pooling Regularized Graph Neural Network for fMRI Biomarker Analysis</b>, <em>Proc.
							International Conference on Medical Image Computing and Computer-Assisted Intervention.
							(MICCAI-20)</em>, 2020. (<a href="https://arxiv.org/pdf/2007.14589.pdf">PDF</a>)</li>

					<h3 style="font-size:15px"><a name="year">2019</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-19]</font>
						</strong> <strong>M. Zhang</strong>, S. Jiang, Z. Cui, R. Garnett, and Y. Chen, <b>D-VAE: A
							Variational Autoencoder for Directed Acyclic Graphs</b>, <em>Advances in Neural Information
							Processing Systems (NeurIPS-19)</em>, 2019. (<a
							href="https://arxiv.org/pdf/1904.11088.pdf">PDF</a>)(<a
							href="https://github.com/muhanzhang/DVAE" target="_blank">Source code</a>) </li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[BJA-19] </font>
						</strong>B. Fritz, Z. Cui, <strong>M. Zhang</strong>, Y. He, Y. Chen, A. Kronzer, A. Ben
						Abdallah,
						C. King, M. Avidan, <b>A Deep Learning Model for Predicting 30-day Postoperative Mortalit</b>,
						<em>British Journal of Anaesthesia (BJA-19)</em>, 2019. (<a
							href="https://www.sciencedirect.com/science/article/abs/pii/S0007091219306361">PDF</a>)
					</li>
					<h3 style="font-size:15px"><a name="year">2018</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[NeurIPS-18] </font>
						</strong><strong>M. Zhang</strong> and Y. Chen, <b>Link Prediction Based on Graph Neural
							Networks</b>, <em>Advances in Neural Information Processing Systems (NeurIPS-18)</em>,
						<font color=#FF4500>spotlight
							presentation</font>, 2018. (Only <font color=#FF4500>168 out of 4856</font> submissions are
						accepted as spotlight presentations)
						(<a href="https://arxiv.org/pdf/1802.09691.pdf">PDF</a>)(<a
							href="https://github.com/muhanzhang/SEAL" target="_blank">Source code</a>)(<a
							href="https://muhanzhang.github.io/SEAL_website/SEAL.html" target="_blank">Website</a>)(<a
							href="https://www.youtube.com/watch?v=a-3iFSQEZ2k&list=PLQ-RH60jtC9JqPqZq66WIjg3uk1P9U3EC&index=9&t=0s"
							target="_blank">Video</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[AAAI-18] </font>
						</strong><strong>M. Zhang</strong>, Z. Cui, M. Neumann, and Y. Chen, <b>An End-to-End Deep
							Learning
							Architecture for Graph Classification</b>, <em>Proc. AAAI Conference on Artificial
							Intelligence
							(AAAI-18),</em> 2018. (<a
							href="http://muhanzhang.github.io/papers/AAAI_2018_DGCNN.pdf">PDF</a>)(<a
							href="http://muhanzhang.github.io/papers/AAAI_2018_DGCNN_appendix.pdf">Supplement</a>)(<a
							href="https://github.com/muhanzhang/DGCNN" target="_blank">Source code</a>) </li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[AAAI-18] </font>
						</strong><strong>M. Zhang</strong>, Z. Cui, S. Jiang, and Y. Chen, <b>Beyond Link Prediction:
							Predicting Hyperlinks in Adjacency Space</b>, <em>Proc. AAAI Conference on Artificial
							Intelligence (AAAI-18),</em> 2018. (<a
							href="http://muhanzhang.github.io/papers/AAAI_2018_Hyperlink.pdf">PDF</a>)(<a
							href="https://github.com/muhanzhang/HyperLinkPrediction" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[ICBK-18] </font>
						</strong>Z. Cui, <strong>M. Zhang</strong>, and Y. Chen, <b>Deep Embedding Logistic
							Regression</b>,
						<em>Proc. IEEE International Conference on Big Knowledge (ICBK-18)</em>, 2018. (<a
							href="https://www.cse.wustl.edu/~ychen/public/DELR.pdf">PDF</a>)
					</li>
					<h3 style="font-size:15px"><a name="year">2017</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[KDD-17] </font>
						</strong><strong>M. Zhang</strong> and Y. Chen, <b>Weisfeiler-Lehman Neural Machine for Link
							Prediction</b>, <em>Proc. ACM SIGKDD Conference on Knowledge Discovery and Data Mining
							(KDD-17),</em>
						<font color=#FF4500>oral presentation</font>, 2017. (Only <font color=#FF4500>64 out of 748
						</font> submissions are accepted as oral
						presentations) (<a href="http://muhanzhang.github.io/papers/KDD_2017.pdf">PDF</a>)(<a
							href="https://youtu.be/dRC4T2gABS8" target="_blank">Video</a>)(<a
							href="https://muhanzhang.github.io/papers/wlnm_muhan.pptx">Slides</a>)(<a
							href="https://github.com/muhanzhang/LinkPrediction" target="_blank">Source code</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[Bioinformatics-17] </font>
						</strong>T. Oyetunde*, <strong>M. Zhang*</strong>, Y. Chen, Y. Tang, and C. Lo,
						<strong>BoostGAPFILL: Improving the fidelity of metabolic network reconstructions through
							integrated
							constraint and pattern-based methods,</strong> &nbsp;<em>Bioinformatics</em>, 33(4):608-611,
						2017. (*co-first author) (<a
							href="https://muhanzhang.github.io/papers/Bioinformatics_2016.pdf">PDF</a>)
					</li>

					<h3 style="font-size:15px"><a name="year">2016</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[BMC Bioinformatics-16] </font>
						</strong>L. He, S. Wu, <strong>M. Zhang</strong>, Y. Chen, and Y. Tang, <strong>WUFlux: an
							open-source platform for 13C metabolic flux analysis of bacterial metabolism</strong>,
						&nbsp;<em>BMC Bioinformatics</em>, 17.1 (2016): 444. (<a href="papers/BMC_2016.pdf">PDF</a>)
					</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[TNNLS-16] </font>
						</strong>W. Cai, <strong>M. Zhang</strong>, and Y. Zhang, <strong>Batch Mode Active Learning for
							Regression With Expected Model Change</strong>, &nbsp;<em>IEEE Transactions on Neural
							Networks
							and Learning Systems (TNNLS) </em>, (2016): 1-14. (<a href="papers/TNNLS_2016.pdf">PDF</a>)
						<h3 style="font-size:15px"><a name="year">2015</a></h3>

					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[IRJ-15] </font>
						</strong>W. Cai, <strong>M. Zhang</strong>, and Y. Zhang, <strong> Active learning for ranking
							with
							sample density</strong>, &nbsp;<em>Information Retrieval Journal </em>, 18.2 (2015):
						123-144.
						(<a href="papers/IRJ_2015.pdf">PDF</a>)</li>
					<li class=MsoNormal> <strong>
							<font color=#0aa0c0>[TWEB-15] </font>
						</strong>W. Cai, <strong>M. Zhang</strong>, and Y. Zhang, <strong> Active learning for Web
							search
							ranking via noise injection</strong>, &nbsp;<em>ACM Transactions on the Web (TWEB)</em>, 9.1
						(2015): 3. (<a href="papers/TWEB_2015.pdf">PDF</a>)</li>
				</ul>
				<hr>
			</div>
			<!-- <div class="group">
				<h3><a name="group">Group</a></h3>
				<p>Haotong Yang, PhD Student, PKU 2021 (co-advised with Zhouchen Lin)</p>
				<p>Xiyuan Wang, PhD Student, PKU 2022</p>
				<p>Fanxu Meng, PhD Student, PKU 2022</p>
				<p>Xiaojuan Tang, PhD Student, PKU 2022 (co-advised with Song-Chun Zhu)</p>
				<p>Zian Li, PhD Student, PKU 2023</p>
				<p>Yanbo Wang, PhD Student, PKU 2023</p>
				<p>Lecheng Kong, PhD Student, WashU</p>
				<p>Jiarui Feng, PhD Student, WashU</p>
				<p>Zehao Dong, PhD Student, WashU</p>
				<p>Hao Liu, PhD Student, WashU</p>
				<p>Xingang Peng, PhD Student, PKU</p>
				<p>Zuoyu Yan, PhD Student, PKU</p>
				<p>Junru Zhou, Undergraduate, PKU</p>
				<p>Yuran Xiang, Undergraduate, PKU</p>
				<p>Cai Zhou, Undergraduate, THU</p>
				<p>Yi Hu, Undergraduate, PKU</p>
				<h4><a name="alumni">Alumni</a></h4>
				<p>Yinan Huang, Research Intern, BIGAI</p>
				<p>Yang Hu, Research Intern, PKU</p>
				<p>Yuxin Yang, Research Intern, BIGAI</p>
				<p>Zhaohui Wang, PhD Student, ICT-CAS</p>
				<hr>

			</div> -->
			<div class="code">
				<h3><a name="code">Software</a></h3>
				<p><a target="_blank" href="https://github.com/muhanzhang/IGMC">IGMC (Inductive Graph-based Matrix
						Completion)</a></p>
				<p3>Code for paper "Inductive Matrix Completion Based on Graph Neural Networks"</p3>
				<p><a target="_blank" href="https://github.com/muhanzhang/D-VAE">D-VAE (DAG Variational Autoencoder)</a>
				</p>
				<p3>Code for paper "D-VAE: A Variational Autoencoder for Directed Acyclic Graphs" on NeurIPS 2019</p3>
				<p><a target="_blank" href="https://github.com/muhanzhang/SEAL">SEAL (learning from Subgraphs,
						Embeddings,
						and Attributes for Link prediction)</a></p>
				<p3>Code for paper "Link Prediction Based on Graph Neural Networks" on NeurIPS 2018</p3>
				<p><a target="_blank" href="https://github.com/muhanzhang/DGCNN">DGCNN (Deep-Graph-CNN)</a></p>
				<p3>Code for paper "An End-to-End Deep Learning Architecture for Graph Classification" on AAAI 2018</p3>
				<p><a target="_blank" href="https://github.com/muhanzhang/HyperLinkPrediction">Hyperlink Prediction
						Toolbox</a></p>
				<p3>Code for paper "Beyond Link Prediction: Predicting Hyperlinks in Adjacency Space" on AAAI 2018</p3>
				<p><a target="_blank" href="https://github.com/muhanzhang/LinkPrediction">WLNM (Weisfeiler-Lehman Neural
						Machine)</a></p>
				<p3>Code for paper "Weisfeiler-Lehman Neural Machine for Link Prediction" on KDD 2017</p3>
			</div>
		</div>
	</div>

</body>

</html>
